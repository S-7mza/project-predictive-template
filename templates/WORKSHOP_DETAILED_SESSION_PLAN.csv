#,Session,When (relative),Duration,Pre-work lead,Required participants,Dependency,Priority,Deliverables
1,Kickoff,"Week 0","60–90 min","3 days","Sponsor; Product Owner; Data Science Lead; ML Engineers",None,"CRITICAL (High)","Updated docs/PROJECT_BRIEF.md; meeting minutes (templates/MEETING_MINUTES.md); action items in templates/ACTION_LOG.csv; initial templates/RACI.md entries; communication/COMM_01_KICKOFF.md"
2,Data & Feature Discovery (deep),"Weeks 1–3","90–120 min (may repeat per source)","5–7 days","Data Owners; Data Engineers; Data Scientists; ML Engineers","Kickoff","CRITICAL (High)","Completed deliverables/DATA_INVENTORY.md; feature source catalog; sample datasets; historical data assessment; data quality notes; communication/COMM_02_DATA_DISCOVERY.md"
2a,"Security, Privacy & Compliance","Weeks 0–1 (parallel/early)","60 min","3–5 days","Security/Compliance; Data Owner; Data Science Lead","Kickoff (or before Data Discovery)","CRITICAL (High if PII)","Data classification register; feature masking rules; compliance sign-offs; model fairness requirements; updated docs/DATA_GOVERNANCE.md; communication/COMM_02A_SECURITY_PRIVACY.md"
3,Feature Engineering & Data Prep,"Weeks 3–4","90–120 min","3–5 days","Data Science Lead; Data Engineers; ML Engineers; Data Owner","Data Discovery","CRITICAL (High)","Feature engineering pipeline; training/validation/test splits; feature store setup; documented in deliverables/ARCHITECTURE.md and deliverables/MODEL_SPEC.md mappings; communication/COMM_03_MODELING.md"
4,Model Selection & Training Design,"Weeks 4–5","90 min","3–5 days","Data Scientists; ML Engineers; Data Owner; MLOps","Feature Engineering","CRITICAL (High)","Model selection criteria; training pipeline design; hyperparameter tuning strategy; experiment tracking setup; model registry configuration (scripts/README.md); communication/COMM_04_ETL_DESIGN.md"
5,"Model Training & Experimentation","Weeks 5–7","90 min","3 days","Product Owner; Data Scientists; ML Engineers","Feature Engineering; some baseline models",High,"Trained baseline and candidate models; model performance reports; finalized deliverables/MODEL_SPEC.md; deliverables/PREDICTION_OUTPUT_SPEC.md; model artifacts in registry; communication/COMM_05_DASHBOARD_DESIGN.md (for model-consumption UX)"
6,"Model Validation & Performance Testing","Weeks 7–8","60–90 min","3 days","QA Lead; Data Scientists; ML Engineers; Data Owner","Models trained and registered",High,"Model validation plan and test cases; cross-validation and holdout results; bias and fairness analysis; performance benchmark report; A/B testing framework; communication/COMM_06_QA_VALIDATION.md"
7,Model Deployment & Monitoring,"Weeks 8–9","60 min","3–5 days","MLOps; Data Science Lead; Security","Validation pass",Medium,"Model deployment pipeline; inference endpoints (batch/real-time); monitoring dashboards; drift detection setup; model versioning and rollback procedures; communication/COMM_07_DEPLOYMENT_MONITORING.md"
8,Stakeholder Demo & Handoff,"Weeks 9–10","60–90 min","3 days","Training lead; Product Owner; end-users; business stakeholders","Deployed model",Medium,"Prediction demo and use case examples; model user guide; confidence score interpretation; completed follow_up/FUP_TEMPLATE.md; sign-off document; communication/COMM_08_TRAINING_HANDOFF.md"
9,Retrospective & Model Performance Review,"Weeks 10–11","45–60 min","2–3 days","Data Science Lead; Data Owner; MLOps; Product Owner","Post-deployment monitoring data",Low,"Retrospective notes; lessons-learned document; model monitoring backlog; initial performance report (docs/BENEFITS_REALIZATION.md update); retraining triggers; communication/COMM_09_RETRO_BENEFITS.md"
